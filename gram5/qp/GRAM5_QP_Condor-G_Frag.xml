<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE section PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN"
"http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd">

    <section id="gram5-reports-condorg">
        <title>GRAM5 Condor-G Tests</title>
        <indexterm type="gram5"><primary>GRAM5 Condor-G Test Results</primary></indexterm>

<para>
   
</para>

    <section id="gram5-reports-condorg-configuration">
    <title>Experiment Hardware and Software Configuration</title>

    <para>
    The following experiments were run on the
    <systemitem class="systemname">nomer.mcs.anl.gov</systemitem> virtual
    cluster. The cluster consists of 6 partitions, each having a single
    <hardware>Intel(R) Xeon(R) CPU E5430 @ 2.66GHz</hardware> core, and 2GB
    RAM. The virtual machines in the cluster each had a single virtual network
    interface. The cluster was configured as follows:

    <itemizedlist>
        <listitem><simpara>1 node: Master node</simpara></listitem>
        <listitem><simpara>1 nodes: Test/execution nodes</simpara></listitem>
        <listitem><simpara>4 nodes: execution nodes</simpara></listitem>
    </itemizedlist>
    </para>

    <para>
    All nodes ran an <command>apache2</command> http server,
    <command>gmond</command> (ganglia monitoring), and
    <command>pbs_mom</command> (torque LRM).
    </para>

    <para>
        The master node also ran a <command>globus-gatekeeper</command>,
        <command>globus-gridftp-server</command>,
        <command>globus-job-manager-event-generator</command>,
        <command>gmetad</command> (Ganglia Meta Daemon),
        <command>pbs_sched</command> (Torque LRM scheduler),
        <command>pbs_server</command> (Torque LRM server), and
        <command>nfsd</command> linux kernel NFSv4 server for the execution
        nodes.
    </para>

    <para>
        The test/execution node ran the
        condor-g daemons. The condor job classified ad included attributes to
        submit the jobs to the GRAM5 service running on the service node. The
        tests were done with Condor version 7.4.1. The Condor-G configuration
        parameters in the <filename>condor_config</filename> file were as
        follows:
    </para>

    <figure>
        <title>Condor-G Experiment Configuration</title>
        <programlisting>GRIDMANAGER_MAX_PENDING_SUBMITS_PER_RESOURCE=50
GRIDMANAGER_MAX_SUBMITTED_JOBS_PER_RESOURCE=2000
GRIDMANAGER_MAX_PENDING_REQUESTS=50
GRIDMANAGER_JOB_PROBE_INTERVAL=300
GRIDMANAGER_MAX_JOBMANAGERS_PER_RESOURCE=0
ENABLE_GRID_MONITOR=FALSE
GRIDMANAGER_DEBUG= D_FULLDEBUG
GRIDMANAGER_GLOBUS_COMMIT_TIMEOUT=12000</programlisting>
    </figure>

    <para>The execution nodes executed the test job executables as scheduled
    by the LRM.
    </para>

    <para>
    For this test, the test/execution node and the execution nodes where
    configured to run up 20 job processes each simultaneously.
    </para>


    </section>

    <section>
    <title>Experiment Scenario</title>

    <para>
        This test submitted a 2000 job condor job cluster, using the following
        classified ad:
    </para>

    <figure>
        <title>Condor-G Classified Ad</title>
        <programlisting>Universe=grid
grid_resource = gt5 nomer1.mcs.anl.gov:2119/jobmanager-pbs
executable=/bin/sleep
arguments=300
transfer_executable=False
stream_output = False
stream_error  = False
output = test.out.$(Process)
error  = test.err.$(Process)
log    = test.log
notification=Never
queue 2000</programlisting>
    </figure>

    <para>
        The configuration parameters are similar to the GRAM5 tests described
        in <olink targetptr="gram5-reports-throughput">GRAM5 Throughput
        Tests</olink> section. The key difference being that this test runs 
        until all 2000 jobs have completed and does not submit any jobs after
        the maximum of 2000 has been reached.
    </para>

    <para>
        To provide a point of comparison, another test using similar parameters
        was run using the <command>gram-throughput-tester</command> program 
        in place of Condor-G. Note that the Condor-G service provides file
        staging and a scratch directory beyond what the throughput tester 
        job did.
    </para>

    <para>
        The two experiments consist of:

        <table>
            <title>GRAM5 Condor-G Experiments</title>

            <tgroup cols="5">
                <thead>
                    <row>
                        <entry>Experiment Name</entry>
                        <entry>LRM monitoring method</entry>
                        <entry>Number of clients</entry>
                        <entry>Number of users</entry>
                        <entry>Total number of jobs</entry>
                    </row>
                </thead>
                <tbody>
                    <row>
                        <entry>Condor-G</entry>
                        <entry>SEG</entry>
                        <entry>1</entry>
                        <entry>1</entry>
                        <entry>2000</entry>
                    </row>
                    <row>
                        <entry>Throughput Tester</entry>
                        <entry>SEG</entry>
                        <entry>1</entry>
                        <entry>1</entry>
                        <entry>2000</entry>
                    </row>
                </tbody>
            </tgroup>
        </table>
    </para>
    </section>

    <section>
    <title>Condor-G Test Results</title>

    <para>
    The following table contains a summary of the results of these experiments.
    The columns contain the following information:

    <variablelist>
        <varlistentry>
            <term>Experiment</term>
            <listitem><simpara>Experiment name, the same as in the previous
            section</simpara></listitem>
        </varlistentry>
        <varlistentry>
            <term>Time to Submit 2000 Jobs</term>
            <listitem><simpara>The total number of GRAM jobs that were
            <emphasis>submitted</emphasis> to the GRAM5 service by the
            throughput tester in one hour.</simpara></listitem>
        </varlistentry>
        <varlistentry>
            <term>Time For All Jobs To Complete</term>
            <listitem><simpara>The amount of time it took for all 2000 jobs to
            complete. The theoretical minimum value for this is 50 minutes
            if all 2000 jobs were submitted instantaneously and there was
            no overhead for them to be deployed to the 200 execution nodes.
            </simpara></listitem>
        </varlistentry>
        <varlistentry>
            <term>LRM Submit Rate (Jobs/Minute)</term>
            <listitem><simpara>The total number of jobs that were being managed
            by the GRAM5 service when the one hour test period elapsed. These
            jobs were terminated using the GRAM5 cancel protocol message by the
            throughput tester.</simpara></listitem>
        </varlistentry>
        <varlistentry>
            <term>Master Node Max 1 min. Load Average</term>
            <listitem><simpara>The maximum value of the one-minute load average
            on the master node, that is, the node running the GRAM5 and Torque
            service.</simpara></listitem>
        </varlistentry>
        <varlistentry>
            <term>Master Node Average 1 min. Load Average</term>
            <listitem><simpara>The average value of the one-minute load average
            on the master node over the duration of the
            test.</simpara></listitem>
        </varlistentry>
    </variablelist>
    <table>
        <title>GRAM5 Throughput Tester Results Summary</title>
        <tgroup cols="6">
            <thead>
                <row>
                    <entry>Experiment</entry>
                    <entry>Time to Submit 2000 Jobs (hh:mm:ss)</entry>
                    <entry>Time For All Jobs To Complete (hh:mm:ss)</entry>
                    <entry>LRM Submit Rate (Jobs/Minute)</entry>
                    <entry>Master Node Max 1 min. Load Average</entry>
                    <entry>Master Node Average 1 min. Load Average</entry>
                </row>
            </thead>
            <tbody>
                <row>
                    <entry>Condor-G</entry>
                    <entry>00:32:34</entry>
                    <entry>02:00:56</entry>
                    <entry>94</entry>
                    <entry>6.56</entry>
                    <entry>1.64</entry>
                </row>

                <row>
                    <entry>Throughput Tester</entry>
                    <entry>00:17:58</entry>
                    <entry>01:54:49</entry>
                    <entry>111</entry>
                    <entry>2.43</entry>
                    <entry>0.53</entry>
               </row>
            </tbody>
        </tgroup>
    </table>
    </para>
    </section>
</section>
